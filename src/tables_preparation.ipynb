{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from data_import import initialize,connection\n",
    "from functions import get_connection , use_database\n",
    "from constants import *\n",
    "from pandasql import sqldf\n",
    "from sqlalchemy.engine import Engine, Connection\n",
    "from sqlalchemy.sql import text\n",
    "from sqlalchemy import select ,MetaData, Table, and_, insert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection: Engine=get_connection(host_name=HOST_NAME, user_name=USER_NAME, user_password=USER_PASSWORD)\n",
    "connection=use_database(connection=connection, database_name=GENDER_BASE_VIOLENCE_DATA_BASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_df=pd.read_csv(r'/Users/angelaivonnesalgadobeltran/Documents/IronHack/Final project/cleaning_data/final_data_calls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We need an index from the very begining in order to keep track of calls observation. DataFrame [Index] will be the staging table index. We index to start from 1 intead of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59360"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calls_df.index += 1\n",
    "calls_df.to_sql(name=\"staging\", index=True, index_label='id',\n",
    "                con=connection, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Feeding localization table from a new dataframe. extract distinc values and inserting to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "location: DataFrame=calls_df[['prov_residencia_persona_en_situacion_violencia', 'media_edad']].drop_duplicates()\n",
    "location.rename(columns={'prov_residencia_persona_en_situacion_violencia':'region_name', 'media_edad':'mean_age'}, inplace=True)\n",
    "location.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "location.to_sql(name=LOCALIZATION_TABLE_NAME, index=False,\n",
    "                con=connection, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Feeding calls table. Unfortunately this method is to heavy and not efficient for this procedure. \n",
    "We needed to loop on each row and insert it based on conditions ---> database conection is too long (approximately 10 000 rec per 20min). \n",
    "We decided to insert the whole data source into one srtaging table and perform feeding through SQL queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_calls(conn: Connection, row):\n",
    "    metadata = MetaData(bind=None)\n",
    "    calls = Table(\n",
    "        'calls',\n",
    "        metadata,\n",
    "        autoload=True,\n",
    "        autoload_with=connection\n",
    "    )\n",
    "    result = conn.execute(insert(calls),\n",
    "                            {\n",
    "                            \"call_date\": {row['fecha']},\n",
    "                            \"id_localization\": {row['id_localization']},\n",
    "                            \"victim_gender\": {row['genero_persona_en_situacion_de_violencia']},\n",
    "                            \"victim_age\": {row['edad']},\n",
    "                            \"aggressor_gender\": {row['genero_de_la_persona_agresora']},\n",
    "                            \"link\": {row['vinculo_con_la_persona_agresora']}\n",
    "    })\n",
    "\n",
    "\n",
    "def get_localization_id(conn:Connection,region_name) -> int:\n",
    "    metadata = MetaData(bind=None)\n",
    "    localization = Table(\n",
    "        'localization',\n",
    "        metadata,\n",
    "        autoload=True,\n",
    "        autoload_with=connection\n",
    "    )\n",
    "    statement = localization.select().with_only_columns(localization.columns.id).where(\n",
    "        localization.columns['region_name'] == region_name)\n",
    "\n",
    "    return conn.execute(statement=statement).first()[0]\n",
    "\n",
    "def insert_into_call():\n",
    "    with connection.begin() as conn:\n",
    "        for _, row in calls_df.iterrows():\n",
    "            id_localization = get_localization_id(conn,\n",
    "                row['prov_residencia_persona_en_situacion_violencia'])\n",
    "            print(id_localization)\n",
    "            row['id_localization'] = id_localization\n",
    "            insert_into_calls(conn=conn,row=row)\n",
    "\n",
    "\n",
    "# not used at the end --> too slow , feeding through feeding.sql script "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2cbc3b52abc8e06b49e1ca36d2c5594418131a07976fda795c55fb6bf71fd75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
